%YAML:1.0

# # Multiple thread support
# multiple_thread: 0

# # segmmentation
# segment_cloud: 1
# horizon_scan: 1800
# min_cluster_size: 30
# segment_valid_point_num: 5
# segment_valid_line_num: 3
# segment_theta: 1.047 # Lego-loam: 1.047

# # laser parameters
# idx_ref: 0
# n_scans: 32
# num_of_laser: 2

# cloud_topic:
#    - "/left/velodyne_points"
#    - "/right/velodyne_points"

# # window sizes
# window_size: 3
# opt_window_size: 1

# # Extrinsic parameter between IMU and Camera.
# estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
#                         # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
#                         # 2  Have no prior about extrinsic parameters. We will initialize and optimize around them

# # the extrinsics from the base_link to laser_link
# # qx qy qz qw px py pz
# body_T_laser: !!opencv-matrix
#    rows: 2
#    cols: 7
#    dt: d
# # no prior
#    # data: [0, 0, 0, 1, 0, 0, 0, 
#    #        0, 0, 0, 1, 0, 0, 0]
# # initialization
#    # data: [0, 0, 0, 1, 0, 0, 0, 
#    #        0, 0, 0, 1, 0, -1, 0]
# # refinement
#    data: [0, 0, 0, 1, 0, 0, 0,
#           0.004008, 0.000008, 0.00099912, 0.9999, -0.0038006, -0.89758, -0.0031404]

# #unsynchronization parameters
# estimate_td: 0                      # 0 have an accurate time offset among sensors
#                                     # 1 online estimate time offset among sensors

# td: !!opencv-matrix                 # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)
#    rows: 1
#    cols: 2
#    dt: d
#    data: [0, 0]

# distortion: 0
# scan_period: 0.05
# laser_sync_threshold: 0.07

# ######################################################## odometry
# # optimization 
# max_solver_time: 0.02  # max solver itration time (s), to guarantee real time
# max_num_iterations: 10   # max solver itrations, to guarantee real time

# roi_range: 1
# distance_sq_threshold: 25
# nearby_scan: 2.5

# # movement type
# planar_movement: 1

# # feature corresponding paprameters
# min_match_sq_dis: 1.0
# min_plane_dis: 0.2

# # factor
# marginalization_factor: 1
# point_plane_factor: 1
# point_edge_factor: 1
# prior_factor: 0
# prior_factor_pos: 5
# prior_factor_rot: 1

# pcl_viewer: 0
# pcl_viewer_normal_ratio: 10

# # calibration converage parameters
# n_cumu_feature: 10
# eig_initial: 400
# eig_thre_calib: 1000
# n_calib: 30

# # good feature
# odom_gf_ratio: 0.4

# skip_num_odom_pub: 4

# ######################################################## mapping
# map_corner_res: 0.2
# map_surf_res: 0.4
# map_outlier_res: 0.8
# map_eig_thre: 100

# # good feature
# map_gf_ratio: 0.2
# lambda_1: 7
# lambda_2: 3

# # uncertainty parameter
# # translation, rotation, point (s, phi, zeta)
# uct_ext: !!opencv-matrix
#    rows: 2
#    cols: 6
#    dt: d
#    data: [0, 0, 0, 0, 0, 0,
#          #  0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025]
#           0, 0, 0, 0, 0, 0]

# uct_measurement: !!opencv-matrix
#    rows: 1
#    cols: 3
#    dt: d
#    data: [0.0025, 0.0025, 0.0025]

# trace_threshold_before_mapping: 2
# trace_threshold_after_mapping: 2
